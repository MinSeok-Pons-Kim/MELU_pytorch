{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7cd62a5-6b7e-4626-8255-5207acf873a9",
   "metadata": {},
   "source": [
    "# import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7031658-0032-4262-b2f6-607d55a0c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./ratings.dat', names=['user_id', 'movie_id', 'rating', 'timestamp'],\n",
    "                        sep=\"::\", engine='python')\n",
    "\n",
    "# movie item lists in score data not equal to movies_extrainfos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b605982-72be-4902-ace5-77974d3540f8",
   "metadata": {},
   "source": [
    "Cold-warm transition with head \\& short-tail items\n",
    "1. Sort interactions by time\n",
    "2. Plot transition ratio\n",
    "3. Warm-cold user similarity\n",
    "4. Popularity bias metrics: which to show? (item or user side?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "362ca547-b1ec-40db-a309-f0c09d13131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_thres = 20\n",
    "movie_cnt = df.movie_id.value_counts()\n",
    "movie_freq = movie_cnt[movie_cnt>=freq_thres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "44b0089f-d414-4c4a-8bc1-70e1baf9da8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items: 3704\n",
      " Freq items: 3043\n",
      " Freq ratio: 0.82\n"
     ]
    }
   ],
   "source": [
    "print(\"Total items: {}\\n Freq items: {}\\n Freq ratio: {:.2f}\".format(len(movie_cnt), len(movie_freq), len(movie_freq)/len(movie_cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6d8135e-42ff-485d-9b02-437bac7ce271",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions: 995492\n",
      "Total users: 6040\n",
      "Total items: 3043\n"
     ]
    }
   ],
   "source": [
    "movie_freq_set = set(movie_freq.index)\n",
    "score_data = df.loc[df.movie_id.apply(lambda movie: movie in movie_freq_set)]\n",
    "\n",
    "# sanity check\n",
    "assert len(set(score_data.movie_id.unique())) == len(movie_freq)\n",
    "assert score_data.movie_id[0] in movie_freq_set\n",
    "\n",
    "print(\"Total interactions: {}\".format(len(score_data)))\n",
    "print(\"Total users: {}\".format(len(score_data.user_id.unique())))\n",
    "print(\"Total items: {}\".format(len(score_data.movie_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "6c49315b-5a13-4b2a-b3b2-f36421ce6dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dms/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Sort interactions by time\n",
    "score_data.sort_values(by=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "593af845-a55f-4729-9794-e003eaedf5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# popular/tail/niche items (top/bottom 20% popularity)\n",
    "i_sorted = score_data.movie_id.value_counts().index\n",
    "total_items = i_sorted.values\n",
    "pop_items = i_sorted[:int(len(i_sorted)*0.2)].values\n",
    "tail_items = i_sorted[int(len(i_sorted)*0.2):].values\n",
    "niche_items = i_sorted[int(len(i_sorted)*0.8):].values\n",
    "\n",
    "# cold_users\n",
    "n_users = len(score_data.user_id.unique())\n",
    "heavy_users = score_data.user_id.value_counts().head(int(n_users*0.2)).index.values\n",
    "warm_users = score_data.user_id.value_counts().head(int(n_users*0.8)).index.values\n",
    "cold_users = score_data.user_id.value_counts().tail(int(n_users*0.2)).index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7503bf-0d2e-4424-a315-50c87ee5c9b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Do users change after first k interactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "5a2f88dc-af88-4369-b991-fd9432540f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2288788/2115824560.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  score_data['pop'] = score_data['movie_id'].apply(lambda x: 1 if x in pop_items else 0)\n",
      "/tmp/ipykernel_2288788/2115824560.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  score_data['tail'] = score_data['movie_id'].apply(lambda x: 1 if x in tail_items else 0)\n",
      "/tmp/ipykernel_2288788/2115824560.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  score_data['niche'] = score_data['movie_id'].apply(lambda x: 1 if x in niche_items else 0)\n"
     ]
    }
   ],
   "source": [
    "score_data['pop'] = score_data['movie_id'].apply(lambda x: 1 if x in pop_items else 0)\n",
    "score_data['tail'] = score_data['movie_id'].apply(lambda x: 1 if x in tail_items else 0)\n",
    "score_data['niche'] = score_data['movie_id'].apply(lambda x: 1 if x in niche_items else 0)\n",
    "\n",
    "user_pop_cnt = score_data.groupby(['user_id'])['pop']\n",
    "user_tail_cnt = score_data.groupby(['user_id'])['tail']\n",
    "user_niche_cnt = score_data.groupby(['user_id'])['niche']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "04f36f8f-d255-4ce3-8fcf-8af1e7a290d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All user initial 10 interactions: 0.6795\n",
      "All user total interactions: 0.6597\n",
      "Heavy user initial 10 interactions: 0.6726\n",
      "Heavy user total interactions: 0.6200\n"
     ]
    }
   ],
   "source": [
    "_ = score_data.groupby(['user_id'])\n",
    "\n",
    "# Head ratio of first 10 interactions\n",
    "init10 = _.head(10).groupby(['user_id'])\n",
    "init_head_ratio = init10['pop'].sum()/init10['pop'].count()\n",
    "\n",
    "# Head ratio of total interactions\n",
    "total_head_ratio = _['pop'].sum()/_['pop'].count()\n",
    "\n",
    "# Head ratio of first 10 & total interactions by 100+ interaction users\n",
    "heavy100 = _.filter(lambda x: len(x) >=100).groupby(['user_id'])\n",
    "\n",
    "heavy100_init10 = heavy100.head(10).groupby(['user_id'])\n",
    "init_head_ratio_heavy100 = heavy100_init10['pop'].sum()/heavy100_init10['pop'].count()\n",
    "\n",
    "total_head_ratio_heavy100 = heavy100['pop'].sum()/heavy100['pop'].count()\n",
    "\n",
    "print(\"All user initial 10 interactions: {:.4f}\".format(init_head_ratio.mean()))\n",
    "print(\"All user total interactions: {:.4f}\".format(total_head_ratio.mean()))\n",
    "print(\"Heavy user initial 10 interactions: {:.4f}\".format(init_head_ratio_heavy100.mean()))\n",
    "print(\"Heavy user total interactions: {:.4f}\".format(total_head_ratio_heavy100.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "ca3914b8-28a8-4c3d-a989-ce1dc32fcbfd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16(0%) 27(10%) 37(20%) 51(30%) 70(40%) 95(50%) 126(60%) 173(70%) 253(80%) 398(90%) "
     ]
    }
   ],
   "source": [
    "#### about half of users have more than 95(≈100) interactions\n",
    "u_hist_len = score_data.groupby(['user_id']).count().sort_values(['pop']).reset_index()['movie_id']\n",
    "for decile in range(0, 10):\n",
    "    print(\"{}({}%)\".format(u_hist_len[int(len(u_hist_len)*decile/10)], decile*10), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "233a1fce-9b25-4d1f-b224-54867d491ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "movie_dict = pickle.load(open('./m_movie_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ce79e-f0f2-4d50-a755-08c9ea6e0f6d",
   "metadata": {},
   "source": [
    "Divide by users' init clicks and get self-similarity (feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "60c5e4f3-51af-4247-9065-0e05104b2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of users: 6040\n",
      "No initial tail interaction by all users: 5785\n",
      "Ratio of users with no initial tail interaction: 0.042\n"
     ]
    }
   ],
   "source": [
    "all_user_num = len(score_data.user_id.unique())\n",
    "all_user_init_tail_num = len(score_data.groupby(['user_id']).head(10).loc[score_data.groupby(['user_id']).head(10)['pop']==False].user_id.unique())\n",
    "print(\"Total # of users: {}\".format(all_user_num))\n",
    "print(\"No initial tail interaction by all users: {}\".format(all_user_init_tail_num))\n",
    "print(\"Ratio of users with no initial tail interaction: {:.3f}\".format((all_user_num-all_user_init_tail_num)/all_user_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "a09b002a-b427-4ce3-8641-95fabee76af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of users: 6040\n",
      "No initial head interaction by all users: 6040\n",
      "Ratio of users with no initial head interaction: 0.000\n"
     ]
    }
   ],
   "source": [
    "all_user_num = len(score_data.user_id.unique())\n",
    "all_user_init_tail_num = len(score_data.groupby(['user_id']).head(10).loc[score_data.groupby(['user_id']).head(10)['pop']==True].user_id.unique())\n",
    "print(\"Total # of users: {}\".format(all_user_num))\n",
    "print(\"No initial head interaction by all users: {}\".format(all_user_init_tail_num))\n",
    "print(\"Ratio of users with no initial head interaction: {:.3f}\".format((all_user_num-all_user_init_tail_num)/all_user_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "80cc0dab-3078-409a-ad00-9b97a0d23b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequent users (100+ interaction): 2935\n",
      "No initial tail interaction by frequent users: 2816\n",
      "Ratio of users with no initial tail interaction: 0.041\n"
     ]
    }
   ],
   "source": [
    "freq_user_num = len(freq_users.user_id.unique())\n",
    "freq_user_init_tail_num = len(freq_users.groupby(['user_id']).head(10).loc[freq_users.groupby(['user_id']).head(10)['pop']==False].user_id.unique())\n",
    "print(\"frequent users ({}+ interaction): {}\".format(freq_condition, freq_user_num))\n",
    "print(\"No initial tail interaction by frequent users: {}\".format(freq_user_init_tail_num))\n",
    "print(\"Ratio of users with no initial tail interaction: {:.3f}\".format((freq_user_num-freq_user_init_tail_num)/freq_user_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6e439e-24a1-47bf-ac0b-ff093a444a32",
   "metadata": {},
   "source": [
    "for interaction 100+ users,\n",
    "1. similarity between first 10 clicks (1/n) and the rest clicks\n",
    "2. similarity between first 10 clicks (1/n, weighted) and the rest clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "8438d9ec-fa15-4844-be00-a184cc71d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_condition = 100\n",
    "freq_users = score_data.groupby(['user_id']).filter(lambda x: len(x) >=freq_condition)\n",
    "fu_init = freq_users.groupby(['user_id']).head(10)\n",
    "fu_later = freq_users.drop(fu_init.index)\n",
    "\n",
    "# sanity check\n",
    "assert set(fu_init.index.values).intersection(set(fu_later.index.values)) == set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7e220-399e-4d41-bfab-98402123db5b",
   "metadata": {},
   "source": [
    "pop item이 없는 경우에 -> 그냥 pop item interaction similarity로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "3f35822c-3a56-432e-bdab-65e25d0359df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_feature(x, movie_dict):\n",
    "    return movie_dict[x[0]]\n",
    "\n",
    "def get_pair_group_similarity(l, r, movie_dict):\n",
    "    \"\"\"Get group similarity between array l and array r.\n",
    "    Return average similarity of array l elements.\n",
    "    Caution: first column is removed for Movielens data ([:,1:])\n",
    "    \"\"\"\n",
    "    # substitute movie id with dictionary value\n",
    "    l_feature = np.apply_along_axis(get_feature, 0, l, movie_dict).squeeze(0).transpose()[:,1:] # remove ratings\n",
    "    r_feature = np.apply_along_axis(get_feature, 0, r, movie_dict).squeeze(0).transpose()[:,1:] # remove ratings\n",
    "\n",
    "    # similarity between initial/later clicks\n",
    "    lr_sim = cosine_similarity(l_feature, r_feature).mean(1)\n",
    "    \n",
    "    return lr_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "ef2a8844-9eca-4349-ae25-a7058b2339f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headtail_similarity(user_hist, init_idx=10):\n",
    "    \"\"\"Get unweighted cosine similarity between head and tail items\n",
    "    \"\"\"\n",
    "    l = user_hist.iloc[:init_idx]\n",
    "    l_h = l.loc[l['pop'] == True].movie_id.to_numpy().reshape(1,-1)\n",
    "    l_t = l.loc[l['pop'] == False].movie_id.to_numpy().reshape(1,-1)\n",
    "    #l = l.movie_id.to_numpy().reshape(1,-1)\n",
    "\n",
    "    r = user_hist.iloc[init_idx:]\n",
    "    #r_h = r.loc[r['pop'] == True].movie_id.to_numpy().reshape(1,-1)\n",
    "    r_t = r.loc[r['pop'] == False].movie_id.to_numpy().reshape(1,-1)\n",
    "    r = r.movie_id.to_numpy().reshape(1,-1)\n",
    "\n",
    "    lh_rt_sim = get_pair_group_similarity(l_h, r_t, movie_dict).mean()\n",
    "    lh_r_sim = get_pair_group_similarity(l_h, r, movie_dict).mean()\n",
    "\n",
    "    if l_t.size > 0:\n",
    "        lt_rt_sim = get_pair_group_similarity(l_t, r_t, movie_dict).mean()\n",
    "        lt_r_sim = get_pair_group_similarity(l_t, r, movie_dict).mean()\n",
    "    else:\n",
    "        lt_rt_sim, lt_r_sim = 0, 0\n",
    "        \n",
    "    return lh_rt_sim, lh_r_sim, l_h.size, lt_rt_sim, lt_r_sim, l_t.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "a3027d49-1448-4d90-8d9d-54afe0b8f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_sim(init_idx):\n",
    "    lh_rt_sims, lh_r_sims, l_h_sizes, lt_rt_sims, lt_r_sims, l_t_sizes = [], [], [], [], [], []\n",
    "\n",
    "    for freq_user_id in freq_users.user_id.unique():\n",
    "        freq_user_hist = freq_users[freq_users.user_id==freq_user_id]\n",
    "        lh_rt_sim, lh_r_sim, l_h_size, lt_rt_sim, lt_r_sim, l_t_size = get_headtail_similarity(freq_user_hist, init_idx=init_idx)\n",
    "        if l_z_size == 0:\n",
    "            continue\n",
    "\n",
    "        lh_rt_sims.append(lh_rt_sim)\n",
    "        lh_r_sims.append(lh_r_sim)\n",
    "        l_h_sizes.append(l_h_size)\n",
    "        lt_rt_sims.append(lt_rt_sim)\n",
    "        lt_r_sims.append(lt_r_sim)\n",
    "        l_t_sizes.append(l_z_size)\n",
    "\n",
    "    lh_rt_sims = np.array(lh_rt_sims)\n",
    "    lh_r_sims = np.array(lh_r_sims)\n",
    "    l_h_sizes = np.array(l_h_sizes)\n",
    "    lt_rt_sims = np.array(lt_rt_sims)\n",
    "    lt_r_sims = np.array(lt_r_sims)\n",
    "    l_t_sizes = np.array(l_t_sizes)\n",
    "\n",
    "    print(\"Cosine similarity via {} initial interactions\".format(init_idx)) \n",
    "    print('init total & future total: {:.4f}'.format(((lh_r_sims+lt_r_sims)/2).mean()))\n",
    "    print('init total & future tails: {:.4f}'.format(((lh_rt_sims+lt_rt_sims)/2).mean()))\n",
    "    print('init heads & future total: {:.4f}'.format(lh_r_sims.mean()))\n",
    "    print('init heads & future tails: {:.4f}'.format(lh_rt_sims.mean()))\n",
    "    print('init tails & future total: {:.4f}'.format(lt_r_sims.mean()))\n",
    "    print('init tails & future tails: {:.4f}'.format(lt_rt_sims.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "b2d702e8-479e-4ed2-b43f-be2e251af107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity via 30 initial interactions\n",
      "init total & future total: 0.0928\n",
      "init total & future tails: 0.0955\n",
      "init heads & future total: 0.0924\n",
      "init heads & future tails: 0.0929\n",
      "init tails & future total: 0.0931\n",
      "init tails & future tails: 0.0982\n"
     ]
    }
   ],
   "source": [
    "get_avg_sim(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "705f8a09-9e97-4abf-a107-f38214bbbb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity via 20 initial interactions\n",
      "init total & future total: 0.0917\n",
      "init total & future tails: 0.0940\n",
      "init heads & future total: 0.0915\n",
      "init heads & future tails: 0.0914\n",
      "init tails & future total: 0.0920\n",
      "init tails & future tails: 0.0967\n"
     ]
    }
   ],
   "source": [
    "get_avg_sim(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "9e7cc281-6cdb-4304-b3c2-421152cadc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity via 10 initial interactions\n",
      "init total & future total: 0.0889\n",
      "init total & future tails: 0.0901\n",
      "init heads & future total: 0.0902\n",
      "init heads & future tails: 0.0889\n",
      "init tails & future total: 0.0876\n",
      "init tails & future tails: 0.0913\n"
     ]
    }
   ],
   "source": [
    "get_avg_sim(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
